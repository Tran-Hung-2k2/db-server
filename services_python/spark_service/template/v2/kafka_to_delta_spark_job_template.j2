{% set unique_data_types = schema.values() | unique | list %}
from pyspark.sql.types import StructType, StructField, {{ unique_data_types | join(', ') }}

import pyspark
from delta import *

builder = (
    pyspark.sql.SparkSession.builder.appName("Spark_job_template") 
)
spark = configure_spark_with_delta_pip(builder).getOrCreate()

minio_bucket = "{{user_id}}"
dataset = "{{dataset_id}}"
kafka_server = "{{kafka_server}}"
kafka_topic = "{{kafka_topic}}"

schema = StructType([
{%- for field, data_type in schema.items() %}
    StructField("{{ field }}", {{ data_type }}()),
{%- endfor %}
])

from pyspark.sql.functions import from_json
df = (
    spark.readStream 
    .format("kafka") 
    .option("kafka.bootstrap.servers", kafka_server) 
    .option("subscribe", kafka_topic) 
    .option("failOnDataLoss","false")
    .load()
    .selectExpr("CAST(value AS STRING)")
    .select(from_json("value", schema).alias("data"))
    .select("data.*")
{%- if filters %}
    .filter({%- for f in filters %}
    {%- if f.operator|string in ["==", "="] %}
        (col("{{ f.column }}") == "{{ f.value }}")
    {%- elif f.operator|string in [">"] %}
        (col("{{ f.column }}") > {{ f.value }})
    {%- elif f.operator|string in [">=", "=>"] %}
        (col("{{ f.column }}") >= {{ f.value }})
    {%- elif f.operator|string in ["<"] %}
        (col("{{ f.column }}") < {{ f.value }})
    {%- elif f.operator|string in ["<=", "=<"] %}
        (col("{{ f.column }}") <= {{ f.value }})
    {%- elif f.operator|string in ["!="] %}
        (col("{{ f.column }}") != "{{ f.value }}")
    {%- elif f.operator|string in ["in", "IN"] %}
        (col("{{ f.column }}").isin([{{ f.value | join(', ') }}]))
    {%- elif f.operator|string in ["not in", "NOT IN"] %}
        (~col("{{ f.column }}").isin([{{ f.value | join(', ') }}]))
    {%- endif %}{%- if not loop.last %} & {% endif %}{%- endfor %}
)
{%- endif %}
    .writeStream
    .format("delta")
    {%- if partition_column %}
    .partitionBy({{ partition_column | join(', ') }})
    {%- endif %}
    .option("checkpointLocation", f"s3a://{minio_bucket}/{dataset}/checkpoint-kafka")
    .start(f"s3a://{minio_bucket}/{dataset}/kafka")
    .awaitTermination()
)